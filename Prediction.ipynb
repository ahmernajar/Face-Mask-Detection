{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f08442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the libraries we need\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os \n",
    "from PIL import Image\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import requests\n",
    "from functions import read_annot,single_img_predict,get_labels_from_dataset,get_labels_and_predictions, compute_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b22702e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up GPU/CPU device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66107914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the model\n",
    "model = torch.load('torch_model.pth',map_location =device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "081d396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_masks(dataset):\n",
    "\n",
    "    def read_annot(file_name, xml_dir):\n",
    "\n",
    "        bbox = []\n",
    "        labels = []\n",
    "\n",
    "        annot_path = os.path.join(xml_dir, file_name[:-3]+'xml')\n",
    "        tree = ET.parse(annot_path)\n",
    "        root = tree.getroot()\n",
    "        for boxes in root.iter('object'):\n",
    "            ymin = int(boxes.find(\"bndbox/ymin\").text)\n",
    "            xmin = int(boxes.find(\"bndbox/xmin\").text)\n",
    "            ymax = int(boxes.find(\"bndbox/ymax\").text)\n",
    "            xmax = int(boxes.find(\"bndbox/xmax\").text)\n",
    "            label = boxes.find('name').text\n",
    "            bbox.append([xmin,ymin,xmax,ymax])\n",
    "            if label == 'with_mask':\n",
    "                label_idx = 2\n",
    "            elif label == 'mask_weared_incorrect':\n",
    "                label_idx = 0\n",
    "            else:\n",
    "                label_idx = 1\n",
    "            labels.append(label_idx)\n",
    "\n",
    "        return bbox, labels\n",
    "\n",
    "    def single_img_predict(img, model, device, nm_thrs=0.3, score_thrs=0.8):\n",
    "        test_img = transforms.ToTensor()(img).to(device)\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = model(test_img.unsqueeze(0))\n",
    "\n",
    "        # Applying non-maximum suppression\n",
    "        keep_boxes = torchvision.ops.nms(predictions[0]['boxes'], predictions[0]['scores'], nm_thrs)\n",
    "\n",
    "        # Filtering out bounding boxes with scores less than threshold\n",
    "        score_filter = predictions[0]['scores'][keep_boxes] > score_thrs\n",
    "\n",
    "        # Get the filtered results\n",
    "        test_labels = predictions[0]['labels'][keep_boxes][score_filter]\n",
    "\n",
    "        # Count occurrences of each label\n",
    "        correct_count = (test_labels == 2).sum().item()  # Label 2 represents 'with_mask'\n",
    "        not_wearing_count = (test_labels == 1).sum().item()  # Label 1 represents 'not wearing'\n",
    "        incorrect_count = (test_labels == 0).sum().item()  # Label 0 represents 'mask_weared_incorrect'\n",
    "\n",
    "        return [correct_count, incorrect_count, not_wearing_count]  # Returning in the specified order\n",
    "\n",
    "\n",
    "    def get_labels_from_dataset(dataset_dir):\n",
    "        label_counts = []\n",
    "\n",
    "        # Define paths to image and annotation directories\n",
    "        image_dir = os.path.join(dataset_dir)\n",
    "        xml_dir = os.path.join(dataset_dir)\n",
    "\n",
    "        image_files = sorted(os.listdir(image_dir))\n",
    "        xml_files = sorted(os.listdir(xml_dir))\n",
    "\n",
    "        # Ensure consistent ordering of files\n",
    "        image_files.sort()\n",
    "        xml_files.sort()\n",
    "\n",
    "        # Iterate over all files in the annotation directory\n",
    "        for image_file, xml_file in zip(image_files, xml_files):\n",
    "            if xml_file.endswith('.xml'):\n",
    "                # Call read_annot function to get bounding boxes and labels\n",
    "                _, labels = read_annot(xml_file, xml_dir)\n",
    "\n",
    "                # Initialize counters for each label for current image\n",
    "                mask_count = labels.count(2)\n",
    "                without_mask_count = labels.count(1)\n",
    "                incorrect_mask_count = labels.count(0)\n",
    "\n",
    "                # Append label counts and image name for current image to label_counts list\n",
    "                label_counts.append((image_file, mask_count,incorrect_mask_count, without_mask_count))\n",
    "\n",
    "\n",
    "        true = np.array([[item[1], item[2], item[3]] for item in label_counts])\n",
    "\n",
    "\n",
    "        return true\n",
    "\n",
    "    def get_labels_and_predictions(dataset_dir, model, device, nm_thrs=0.3, score_thrs=0.8):\n",
    "        label_counts = []\n",
    "        predictions = []\n",
    "\n",
    "        # Define paths to image and annotation directories\n",
    "        image_dir = os.path.join(dataset_dir)\n",
    "        xml_dir = os.path.join(dataset_dir)\n",
    "\n",
    "        # Ensure consistent ordering of files\n",
    "        image_files = sorted(os.listdir(image_dir))\n",
    "        xml_files = sorted(os.listdir(xml_dir))\n",
    "\n",
    "        # Iterate over all files in the annotation directory\n",
    "        for image_file, xml_file in zip(image_files, xml_files):\n",
    "            if xml_file.endswith('.xml') and image_file.endswith('.jpg') or image_file.endswith('.png'):\n",
    "                # Call read_annot function to get bounding boxes and labels\n",
    "                _, labels = read_annot(xml_file, xml_dir)\n",
    "\n",
    "                # Load image\n",
    "                img_path = os.path.join(image_dir, image_file)\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "                # Predict labels for the image\n",
    "                predicted_counts = single_img_predict(img, model, device, nm_thrs, score_thrs)\n",
    "\n",
    "                # Append file name and predicted counts for current image to label_counts list\n",
    "                label_counts.append((image_file, *labels))\n",
    "                predictions.append((image_file, *predicted_counts))  # Unpack the list of counts\n",
    "\n",
    "        pred = np.array([[item[1], item[2], item[3]] for item in predictions])\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def compute_mape(actual, forecast):\n",
    "        n = actual.shape[0]  # Assuming both arrays have the same number of rows\n",
    "        absolute_errors = np.abs((actual - forecast) / np.maximum(actual, 1))\n",
    "        mape = (1 / n) * np.sum(absolute_errors) * 100\n",
    "        return mape\n",
    "\n",
    "    predictions = get_labels_and_predictions(dataset, model, device)\n",
    "    true = get_labels_from_dataset(dataset)\n",
    "    mape = compute_mape(true, predictions)\n",
    "    \n",
    "    return predictions, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56ae6036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[16,  0,  0],\n",
       "        [ 3,  0,  3],\n",
       "        [ 1,  0,  0],\n",
       "        [ 2,  0,  0],\n",
       "        [ 9,  0,  0],\n",
       "        [ 9,  0,  0],\n",
       "        [ 2,  0,  0],\n",
       "        [13,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 2,  0,  2],\n",
       "        [ 5,  0,  1],\n",
       "        [ 0,  0,  1],\n",
       "        [ 4,  0,  0],\n",
       "        [ 2,  0,  0],\n",
       "        [ 0,  0,  2],\n",
       "        [ 4,  0,  4],\n",
       "        [17,  0,  1],\n",
       "        [ 1,  0,  0],\n",
       "        [ 3,  0,  3],\n",
       "        [ 6,  0,  0],\n",
       "        [ 7,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  1],\n",
       "        [10,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [11,  0,  0],\n",
       "        [ 2,  0, 12],\n",
       "        [ 1,  0,  0],\n",
       "        [12,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [13,  0,  0],\n",
       "        [52,  0,  0],\n",
       "        [ 2,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [15,  0,  5],\n",
       "        [ 2,  0,  0],\n",
       "        [ 2,  0,  0],\n",
       "        [20,  0, 16],\n",
       "        [ 4,  0,  7],\n",
       "        [ 1,  0,  1],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 9,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [11,  0,  2],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 2,  0,  1],\n",
       "        [20,  0,  0],\n",
       "        [ 7,  0,  1],\n",
       "        [ 3,  0,  1],\n",
       "        [ 4,  0,  0],\n",
       "        [ 9,  0,  0],\n",
       "        [ 7,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 5,  0,  0],\n",
       "        [ 4,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 6,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 8,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 2,  0,  0],\n",
       "        [ 2,  0,  0],\n",
       "        [ 3,  0,  0],\n",
       "        [ 4,  0,  1],\n",
       "        [ 6,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [19,  0,  1],\n",
       "        [ 1,  0,  6],\n",
       "        [ 8,  0,  1],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [13,  0,  0],\n",
       "        [ 4,  0,  0],\n",
       "        [ 1,  0,  0],\n",
       "        [ 9,  0,  3],\n",
       "        [ 1,  0,  0]]),\n",
       " 13.90764647467726)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_masks('MaskedFace/val/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
